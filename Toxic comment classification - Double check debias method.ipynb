{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8CYwgiYe58W"
   },
   "source": [
    "**Toxic comment classification - Varify Model Performance against Debias Method**\n",
    "\n",
    "- Split both the original dataset and the dataset which has the sensitive words marked into training and test sets.\n",
    "- Apply tf-idf feature representation method.\n",
    "- Train both datasets with RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1Xg0deRneYM9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JNlds7UVfFV5"
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df_train1 = pd.read_csv('processed_train_data.csv')  # Original data without marking sensitive words\n",
    "df_train2 = pd.read_csv('ready_train.csv')  # Data with sensitive words marking\n",
    "\n",
    "# Vectorize lemmas for dataset 1\n",
    "vectorizer = TfidfVectorizer()\n",
    "X1 = vectorizer.fit_transform(df_train1['lemmas'])\n",
    "y1 = df_train1[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Split data into train and test sets for dataset 1\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
    "\n",
    "# Vectorize lemmas for dataset 2\n",
    "X2 = vectorizer.fit_transform(df_train2['lemmas'])\n",
    "y2 = df_train2[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Split data into train and test sets for dataset 2\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train and evaluate models for both datasets\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXQboMyyiu0W",
    "outputId": "4e67dab5-1ac3-4253-f214-d19f7b6b5d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for dataset 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.58      0.71      4582\n",
      "           1       0.46      0.07      0.12       486\n",
      "           2       0.91      0.62      0.73      2556\n",
      "           3       0.53      0.06      0.11       136\n",
      "           4       0.81      0.46      0.59      2389\n",
      "           5       0.72      0.06      0.11       432\n",
      "\n",
      "   micro avg       0.88      0.51      0.65     10581\n",
      "   macro avg       0.72      0.31      0.39     10581\n",
      "weighted avg       0.85      0.51      0.63     10581\n",
      " samples avg       0.05      0.04      0.05     10581\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model for dataset 1\n",
    "clf.fit(X_train1, y_train1)\n",
    "y_pred1 = clf.predict(X_test1)\n",
    "print(\"Classification report for dataset 1:\")\n",
    "print(classification_report(y_test1, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Q8PXQ0rjUps",
    "outputId": "cc711555-f4cf-4d7e-a5e8-6a8f49f78bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report for dataset 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.58      0.71      4582\n",
      "           1       0.45      0.06      0.11       486\n",
      "           2       0.90      0.62      0.74      2556\n",
      "           3       0.50      0.07      0.13       136\n",
      "           4       0.79      0.46      0.58      2389\n",
      "           5       0.58      0.03      0.06       432\n",
      "\n",
      "   micro avg       0.87      0.51      0.64     10581\n",
      "   macro avg       0.69      0.31      0.39     10581\n",
      "weighted avg       0.84      0.51      0.62     10581\n",
      " samples avg       0.05      0.04      0.05     10581\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model for dataset 2\n",
    "clf.fit(X_train2, y_train2)\n",
    "y_pred2 = clf.predict(X_test2)\n",
    "print(\"\\nClassification report for dataset 2:\")\n",
    "print(classification_report(y_test2, y_pred2))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
